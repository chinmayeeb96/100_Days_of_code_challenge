{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7fdcb66",
   "metadata": {},
   "source": [
    "## Majority_vote_classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "359d6ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import argmax, bincount\n",
    "h_count = argmax(bincount([0,0,0,1], weights =[0.2, 0.6, 0.6, 0.6]))\n",
    "h_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "febf67e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import _name_estimators\n",
    "import numpy as np\n",
    "import operator\n",
    "\n",
    "\n",
    "class MajorityVoteClassifier(BaseEstimator, \n",
    "                             ClassifierMixin):\n",
    "    \"\"\" A majority vote ensemble classifier\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    classifiers : array-like, shape = [n_classifiers]\n",
    "      Different classifiers for the ensemble\n",
    "\n",
    "    vote : str, {'classlabel', 'probability'} (default='classlabel')\n",
    "      If 'classlabel' the prediction is based on the argmax of\n",
    "        class labels. Else if 'probability', the argmax of\n",
    "        the sum of probabilities is used to predict the class label\n",
    "        (recommended for calibrated classifiers).\n",
    "\n",
    "    weights : array-like, shape = [n_classifiers], optional (default=None)\n",
    "      If a list of `int` or `float` values are provided, the classifiers\n",
    "      are weighted by importance; Uses uniform weights if `weights=None`.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, classifiers, vote='classlabel', weights=None):\n",
    "\n",
    "        self.classifiers = classifiers\n",
    "        self.named_classifiers = {key: value for key, value\n",
    "                                  in _name_estimators(classifiers)}\n",
    "        self.vote = vote\n",
    "        self.weights = weights\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\" Fit classifiers.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape = [n_examples, n_features]\n",
    "            Matrix of training examples.\n",
    "\n",
    "        y : array-like, shape = [n_examples]\n",
    "            Vector of target class labels.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "\n",
    "        \"\"\"\n",
    "        if self.vote not in ('probability', 'classlabel'):\n",
    "            raise ValueError(f\"vote must be 'probability' or 'classlabel'\"\n",
    "                             f\"; got (vote={self.vote})\")\n",
    "\n",
    "        if self.weights and len(self.weights) != len(self.classifiers):\n",
    "            raise ValueError(f'Number of classifiers and weights must be equal'\n",
    "                             f'; got {len(self.weights)} weights,'\n",
    "                             f' {len(self.classifiers)} classifiers')\n",
    "\n",
    "        # Use LabelEncoder to ensure class labels start with 0, which\n",
    "        # is important for np.argmax call in self.predict\n",
    "        self.lablenc_ = LabelEncoder()\n",
    "        self.lablenc_.fit(y)\n",
    "        self.classes_ = self.lablenc_.classes_\n",
    "        self.classifiers_ = []\n",
    "        for clf in self.classifiers:\n",
    "            fitted_clf = clone(clf).fit(X, self.lablenc_.transform(y))\n",
    "            self.classifiers_.append(fitted_clf)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\" Predict class labels for X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape = [n_examples, n_features]\n",
    "            Matrix of training examples.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        maj_vote : array-like, shape = [n_examples]\n",
    "            Predicted class labels.\n",
    "            \n",
    "        \"\"\"\n",
    "        if self.vote == 'probability':\n",
    "            maj_vote = np.argmax(self.predict_proba(X), axis=1)\n",
    "        else:  # 'classlabel' vote\n",
    "\n",
    "            #  Collect results from clf.predict calls\n",
    "            predictions = np.asarray([clf.predict(X)\n",
    "                                      for clf in self.classifiers_]).T\n",
    "\n",
    "            maj_vote = np.apply_along_axis(\n",
    "                                      lambda x:\n",
    "                                      np.argmax(np.bincount(x,\n",
    "                                                weights=self.weights)),\n",
    "                                      axis=1,\n",
    "                                      arr=predictions)\n",
    "        maj_vote = self.lablenc_.inverse_transform(maj_vote)\n",
    "        return maj_vote\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\" Predict class probabilities for X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape = [n_examples, n_features]\n",
    "            Training vectors, where n_examples is the number of examples and\n",
    "            n_features is the number of features.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        avg_proba : array-like, shape = [n_examples, n_classes]\n",
    "            Weighted average probability for each class per example.\n",
    "\n",
    "        \"\"\"\n",
    "        probas = np.asarray([clf.predict_proba(X)\n",
    "                             for clf in self.classifiers_])\n",
    "        avg_proba = np.average(probas, axis=0, weights=self.weights)\n",
    "        return avg_proba\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        \"\"\" Get classifier parameter names for GridSearch\"\"\"\n",
    "        if not deep:\n",
    "            return super().get_params(deep=False)\n",
    "        else:\n",
    "            out = self.named_classifiers.copy()\n",
    "            for name, step in self.named_classifiers.items():\n",
    "                for key, value in step.get_params(deep=True).items():\n",
    "                    out[f'{name}__{key}'] = value\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ece3f41f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to operator (<ipython-input-11-53145fc6112d>, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-53145fc6112d>\"\u001b[0;36m, line \u001b[0;32m16\u001b[0m\n\u001b[0;31m    X-train, X-test, y-train, y-test = train_test_split(X,\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m cannot assign to operator\n"
     ]
    }
   ],
   "source": [
    "# importing libraries\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# loading iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data[:, :4]\n",
    "Y = iris.target\n",
    "\n",
    "# train_test_split\n",
    "X-train, X-test, y-train, y-test = train_test_split(X,\n",
    "Y,\n",
    "test-size = 0.20,\n",
    "random-state = 42)\n",
    "\n",
    "# group / ensemble of models\n",
    "estimator = []\n",
    "estimator.append(('LR',\n",
    "LogisticRegression(solver ='lbfgs',\n",
    "multi_class ='multinomial',\n",
    "max_iter = 200)))\n",
    "estimator.append(('SVC', SVC(gamma ='auto', probability = True)))\n",
    "estimator.append(('DTC', DecisionTreeClassifier()))\n",
    "\n",
    "# Voting Classifier with hard voting\n",
    "vot_hard = VotingClassifier(estimators = estimator, voting ='hard')\n",
    "vot_hard.fit(x-train, y-train)\n",
    "Y_prediction = vot_hard.predict(X-test)\n",
    "\n",
    "# using accuracy_score metric to predict accuracy\n",
    "score = accuracy_score(y-test, Y_prediction)\n",
    "print(\"Hard Voting Score % d\" % score)\n",
    "\n",
    "# Voting Classifier with soft voting\n",
    "vot_soft = VotingClassifier(estimators = estimator, voting ='soft')\n",
    "vot_soft.fit(x-train, y-train)\n",
    "Y_prediction = vot_soft.predict(X-test)\n",
    "\n",
    "# using accuracy_score\n",
    "score = accuracy_score(y-test, Y_prediction)\n",
    "print(\"Soft Voting Score % d\" % score)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb18b46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
